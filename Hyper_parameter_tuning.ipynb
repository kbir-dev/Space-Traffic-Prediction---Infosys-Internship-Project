{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozRivH-Hn-cp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "import numpy as np\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "data=pd.read_csv('space_traffic.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Convert 'Timestamp' to datetime format\n",
        "data['Timestamp'] = pd.to_datetime(data['Timestamp'])\n",
        "\n",
        "# Convert 'Peak_Time' to hour (integer)\n",
        "data['Peak_Time'] = data['Peak_Time'].apply(lambda x: int(x.split(':')[0]))\n",
        "\n",
        "# Extract features from the timestamp\n",
        "data['Hour'] = data['Timestamp'].dt.hour\n",
        "data['Day_of_Week'] = data['Timestamp'].dt.dayofweek\n",
        "data['Day_of_Month'] = data['Timestamp'].dt.day\n",
        "\n",
        "# Encode categorical features using LabelEncoder\n",
        "label_encoder_location = LabelEncoder()\n",
        "label_encoder_object = LabelEncoder()\n",
        "\n",
        "data['Location_Encoded'] = label_encoder_location.fit_transform(data['Location'])\n",
        "data['Object_Type_Encoded'] = label_encoder_object.fit_transform(data['Object_Type'])\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data[['Location_Encoded', 'Object_Type_Encoded', 'Hour', 'Day_of_Week', 'Day_of_Month']]\n",
        "y = data['Traffic_Density']\n",
        "\n",
        "# Standardize the target variable\n",
        "scaler = StandardScaler()\n",
        "y = scaler.fit_transform(y.values.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "qUX6FLTVoTWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import joblib\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Rescale the predictions and actual values for evaluation\n",
        "y_test_rescaled = scaler.inverse_transform(y_test)\n",
        "y_pred_rescaled = scaler.inverse_transform(y_pred)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test_rescaled, y_pred_rescaled)\n",
        "r2 = r2_score(y_test_rescaled, y_pred_rescaled)\n",
        "\n",
        "# Output results\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"R² Score: {r2}\")\n",
        "\n",
        "# Display some predictions alongside actual values\n",
        "print(\"\\nSample Predictions:\")\n",
        "for actual, predicted in zip(y_test_rescaled[:10], y_pred_rescaled[:10]):  # Displaying the first 10 values\n",
        "    print(f\"Actual: {actual[0]:.2f}, Predicted: {predicted[0]:.2f}\")\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(model, 'linear_regression_model.pkl')\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQGtt08WoYFy",
        "outputId": "cc6b3b4d-1e1e-4edc-eae7-0baa45f3cb1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 805.5773943591065\n",
            "R² Score: -0.006034119149835648\n",
            "\n",
            "Sample Predictions:\n",
            "Actual: 25.00, Predicted: 48.07\n",
            "Actual: 97.00, Predicted: 49.46\n",
            "Actual: 41.00, Predicted: 50.43\n",
            "Actual: 38.00, Predicted: 46.15\n",
            "Actual: 43.00, Predicted: 52.95\n",
            "Actual: 79.00, Predicted: 47.21\n",
            "Actual: 73.00, Predicted: 49.25\n",
            "Actual: 67.00, Predicted: 47.75\n",
            "Actual: 83.00, Predicted: 48.41\n",
            "Actual: 95.00, Predicted: 51.79\n",
            "Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Cross-validation with 5 folds, using R² score as the metric\n",
        "cv_scores_r2 = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
        "\n",
        "# Mean and standard deviation of cross-validation R² scores\n",
        "print(f\"Cross-validated R² score: {np.mean(cv_scores_r2)}\")\n",
        "print(f\"Standard deviation of R² scores: {np.std(cv_scores_r2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RXaumhuog60",
        "outputId": "1385ea47-27e1-4705-d2b6-e9f488be47c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validated R² score: -0.008935263569921447\n",
            "Standard deviation of R² scores: 0.00532714924995567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid for Ridge Regression\n",
        "ridge_param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Perform Grid Search with Cross-Validation\n",
        "ridge_grid_search = GridSearchCV(Ridge(), ridge_param_grid, cv=5, scoring='r2')\n",
        "ridge_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best Ridge model\n",
        "best_ridge_model = ridge_grid_search.best_estimator_\n",
        "\n",
        "# Make predictions\n",
        "ridge_pred = best_ridge_model.predict(X_test)\n",
        "\n",
        "y_test_rescaled = scaler.inverse_transform(y_test)\n",
        "ridge_pred_rescaled = scaler.inverse_transform(ridge_pred)\n",
        "\n",
        "# Evaluate the model\n",
        "ridge_mse = mean_squared_error(y_test_rescaled, ridge_pred_rescaled)\n",
        "ridge_r2 = r2_score(y_test_rescaled, ridge_pred_rescaled)\n",
        "\n",
        "# Output results\n",
        "print(f\"Ridge Regression - Mean Squared Error (MSE): {ridge_mse}\")\n",
        "print(f\"Ridge Regression - R² Score: {ridge_r2}\")\n",
        "print(f\"Best alpha for Ridge: {ridge_grid_search.best_params_['alpha']}\")\n",
        "print(f\"Best R² score during GridSearchCV: {ridge_grid_search.best_score_}\")\n",
        "\n",
        "# Save the best Ridge model\n",
        "joblib.dump(best_ridge_model, 'best_ridge_model.pkl')\n",
        "print(\"Best Ridge model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q5UZNuIpDHH",
        "outputId": "03f070d6-27af-4fa7-cfa8-0a7d4bd4a606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge Regression - Mean Squared Error (MSE): 805.4744559605903\n",
            "Ridge Regression - R² Score: -0.005905565963260084\n",
            "Best alpha for Ridge: 100\n",
            "Best R² score during GridSearchCV: -0.0177382989718865\n",
            "Best Ridge model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid for Lasso Regression\n",
        "lasso_param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Perform Grid Search with Cross-Validation\n",
        "lasso_grid_search = GridSearchCV(Lasso(max_iter=10000), lasso_param_grid, cv=5, scoring='r2')\n",
        "lasso_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best Lasso model\n",
        "best_lasso_model = lasso_grid_search.best_estimator_\n",
        "\n",
        "# Make predictions\n",
        "lasso_pred = best_lasso_model.predict(X_test)\n",
        "\n",
        "# Rescale the predictions and actual test values to original scale\n",
        "y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "lasso_pred_rescaled = scaler.inverse_transform(lasso_pred.reshape(-1, 1))\n",
        "\n",
        "# Evaluate the model\n",
        "lasso_mse = mean_squared_error(y_test_rescaled, lasso_pred_rescaled)\n",
        "lasso_r2 = r2_score(y_test_rescaled, lasso_pred_rescaled)\n",
        "\n",
        "# Output results\n",
        "print(f\"Lasso Regression - Mean Squared Error (MSE): {lasso_mse}\")\n",
        "print(f\"Lasso Regression - R² Score: {lasso_r2}\")\n",
        "print(f\"Best alpha for Lasso: {lasso_grid_search.best_params_['alpha']}\")\n",
        "print(f\"Best R² score during GridSearchCV for Lasso: {lasso_grid_search.best_score_}\")\n",
        "\n",
        "# Save the best Lasso model\n",
        "joblib.dump(best_lasso_model, 'best_lasso_model.pkl')\n",
        "print(\"Best Lasso model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV9wcNH4pzEH",
        "outputId": "7b9686a2-dfb7-4395-d236-30e355c3d6d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso Regression - Mean Squared Error (MSE): 801.0278265625\n",
            "Lasso Regression - R² Score: -0.00035245471533040806\n",
            "Best alpha for Lasso: 1\n",
            "Best R² score during GridSearchCV for Lasso: -0.00974720749070399\n",
            "Best Lasso model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import joblib\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid for KNN Regressor\n",
        "knn_param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "}\n",
        "\n",
        "# Perform Grid Search with Cross-Validation\n",
        "knn_grid_search = GridSearchCV(KNeighborsRegressor(), knn_param_grid, cv=5, scoring='r2', verbose=1)\n",
        "knn_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best KNN model\n",
        "best_knn_model = knn_grid_search.best_estimator_\n",
        "\n",
        "# Make predictions\n",
        "knn_pred = best_knn_model.predict(X_test)\n",
        "\n",
        "# Rescale the predictions and actual test values to original scale\n",
        "y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "knn_pred_rescaled = scaler.inverse_transform(knn_pred.reshape(-1, 1))\n",
        "\n",
        "# Evaluate the model\n",
        "knn_mse = mean_squared_error(y_test_rescaled, knn_pred_rescaled)\n",
        "knn_r2 = r2_score(y_test_rescaled, knn_pred_rescaled)\n",
        "\n",
        "# Output results\n",
        "print(f\"KNN Regressor - Mean Squared Error (MSE): {knn_mse}\")\n",
        "print(f\"KNN Regressor - R² Score: {knn_r2}\")\n",
        "print(f\"Best parameters for KNN: {knn_grid_search.best_params_}\")\n",
        "print(f\"Best R² score during GridSearchCV for KNN: {knn_grid_search.best_score_}\")\n",
        "\n",
        "# Save the best KNN model\n",
        "joblib.dump(best_knn_model, 'best_knn_model.pkl')\n",
        "print(\"Best KNN model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZm03fI5qXqS",
        "outputId": "73e697a9-4dae-4447-d7c0-98d2edfdcdb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "KNN Regressor - Mean Squared Error (MSE): 890.2504779377429\n",
            "KNN Regressor - R² Score: -0.11177692133149764\n",
            "Best parameters for KNN: {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'distance'}\n",
            "Best R² score during GridSearchCV for KNN: -0.08007791935209156\n",
            "Best KNN model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import joblib\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid for Random Forest Regressor\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the trees\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split a node\n",
        "    'min_samples_leaf': [1, 2, 4],  # Minimum samples required at each leaf node\n",
        "    'bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
        "}\n",
        "\n",
        "# Initialize Random Forest and GridSearchCV\n",
        "rf_grid_search = GridSearchCV(RandomForestRegressor(random_state=42),\n",
        "                              rf_param_grid, cv=5, scoring='r2', verbose=1, n_jobs=-1)\n",
        "\n",
        "rf_grid_search.fit(X_train, y_train.ravel())\n",
        "\n",
        "# Get the best Random Forest model\n",
        "best_rf_model = rf_grid_search.best_estimator_\n",
        "\n",
        "# Make predictions\n",
        "y_pred_rf = best_rf_model.predict(X_test)\n",
        "\n",
        "# Rescale the predictions and actual test values to the original scale\n",
        "y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "y_pred_rf_rescaled = scaler.inverse_transform(y_pred_rf.reshape(-1, 1))\n",
        "\n",
        "# Evaluate the model\n",
        "rf_mse = mean_squared_error(y_test_rescaled, y_pred_rf_rescaled)\n",
        "rf_r2 = r2_score(y_test_rescaled, y_pred_rf_rescaled)\n",
        "\n",
        "# Output results\n",
        "print(f\"Random Forest - Mean Squared Error (MSE): {rf_mse}\")\n",
        "print(f\"Random Forest - R² Score: {rf_r2}\")\n",
        "print(f\"Best parameters for Random Forest: {rf_grid_search.best_params_}\")\n",
        "print(f\"Best R² score during GridSearchCV: {rf_grid_search.best_score_}\")\n",
        "\n",
        "# Save the best Random Forest model\n",
        "joblib.dump(best_rf_model, 'best_random_forest_model.pkl')\n",
        "print(\"Best Random Forest model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvjJjF5Qq-El",
        "outputId": "b2c3dfd9-fff5-4be1-ae04-cfbc1f837e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
            "Random Forest - Mean Squared Error (MSE): 885.138737009281\n",
            "Random Forest - R² Score: -0.10539319480404385\n",
            "Best parameters for Random Forest: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300}\n",
            "Best R² score during GridSearchCV: -0.05173288862346435\n",
            "Best Random Forest model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import joblib\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid for Decision Tree\n",
        "dt_param_grid = {\n",
        "    'max_depth': [None, 5, 10, 20],  # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4],  # Minimum samples required to be at a leaf node\n",
        "    'max_features': [None, 'sqrt', 'log2']  # Number of features to consider for best split\n",
        "}\n",
        "\n",
        "# Initialize Decision Tree and GridSearchCV\n",
        "dt_grid_search = GridSearchCV(DecisionTreeRegressor(random_state=42),\n",
        "                              dt_param_grid, cv=5, scoring='r2', verbose=1, n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV on the training data\n",
        "dt_grid_search.fit(X_train, y_train.ravel())\n",
        "\n",
        "# Extract the best Decision Tree model\n",
        "best_dt_model = dt_grid_search.best_estimator_\n",
        "\n",
        "# Make predictions\n",
        "y_pred_dt = best_dt_model.predict(X_test)\n",
        "\n",
        "# Rescale the predictions and actual test values to the original scale\n",
        "y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "y_pred_dt_rescaled = scaler.inverse_transform(y_pred_dt.reshape(-1, 1))\n",
        "\n",
        "# Evaluate the model\n",
        "dt_mse = mean_squared_error(y_test_rescaled, y_pred_dt_rescaled)\n",
        "dt_r2 = r2_score(y_test_rescaled, y_pred_dt_rescaled)\n",
        "\n",
        "# Output results\n",
        "print(f\"Decision Tree - Mean Squared Error (MSE): {dt_mse}\")\n",
        "print(f\"Decision Tree - R² Score: {dt_r2}\")\n",
        "print(f\"Best parameters for Decision Tree: {dt_grid_search.best_params_}\")\n",
        "print(f\"Best R² score during GridSearchCV: {dt_grid_search.best_score_}\")\n",
        "\n",
        "# Save the best Decision Tree model\n",
        "joblib.dump(best_dt_model, 'best_decision_tree_model.pkl')\n",
        "print(\"Best Decision Tree model saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-I50rmfrtxQ",
        "outputId": "9ffc9791-7f17-4f1a-dfd0-eff8fbf985bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "Decision Tree - Mean Squared Error (MSE): 869.1550832283101\n",
            "Decision Tree - R² Score: -0.08543223119591303\n",
            "Best parameters for Decision Tree: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
            "Best R² score during GridSearchCV: -0.0905079463781348\n",
            "Best Decision Tree model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import joblib\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid for Gradient Boosting\n",
        "gb_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],  # Number of boosting stages to be run\n",
        "    'learning_rate': [0.01, 0.1, 0.2],  # Step size shrinkage to prevent overfitting\n",
        "    'max_depth': [3, 5, 7],  # Maximum depth of individual regression estimators\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split a node\n",
        "    'min_samples_leaf': [1, 2, 4]  # Minimum samples required at a leaf node\n",
        "}\n",
        "\n",
        "# Initialize Gradient Boosting and GridSearchCV\n",
        "gb_grid_search = GridSearchCV(GradientBoostingRegressor(random_state=42),\n",
        "                              gb_param_grid, cv=5, scoring='r2', verbose=1, n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV on the training data\n",
        "gb_grid_search.fit(X_train, y_train.ravel())\n",
        "\n",
        "# Extract the best Gradient Boosting model\n",
        "best_gb_model = gb_grid_search.best_estimator_\n",
        "\n",
        "# Make predictions\n",
        "y_pred_gb = best_gb_model.predict(X_test)\n",
        "\n",
        "# Rescale the predictions and actual test values to the original scale\n",
        "y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "y_pred_gb_rescaled = scaler.inverse_transform(y_pred_gb.reshape(-1, 1))\n",
        "\n",
        "# Evaluate the model\n",
        "gb_mse = mean_squared_error(y_test_rescaled, y_pred_gb_rescaled)\n",
        "gb_r2 = r2_score(y_test_rescaled, y_pred_gb_rescaled)\n",
        "\n",
        "# Output results\n",
        "print(f\"Gradient Boosting - Mean Squared Error (MSE): {gb_mse}\")\n",
        "print(f\"Gradient Boosting - R² Score: {gb_r2}\")\n",
        "print(f\"Best parameters for Gradient Boosting: {gb_grid_search.best_params_}\")\n",
        "print(f\"Best R² score during GridSearchCV: {gb_grid_search.best_score_}\")\n",
        "\n",
        "# Save the best Gradient Boosting model\n",
        "joblib.dump(best_gb_model, 'best_gradient_boosting_model.pkl')\n",
        "print(\"Best Gradient Boosting model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17LNltdVrvGG",
        "outputId": "17af5b7f-d194-46ca-99df-dc2e3b78a1a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
            "Gradient Boosting - Mean Squared Error (MSE): 827.20340028239\n",
            "Gradient Boosting - R² Score: -0.03304145571626016\n",
            "Best parameters for Gradient Boosting: {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Best R² score during GridSearchCV: -0.0033742339245776297\n",
            "Best Gradient Boosting model saved successfully!\n"
          ]
        }
      ]
    }
  ]
}